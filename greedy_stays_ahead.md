# [Greedy stays ahead](https://web.stanford.edu/class/archive/cs/cs161/cs161.1138/handouts/120%20Guide%20to%20Greedy%20Algorithms.pdf)

One of the simplest methods for showing that a greedy algorithm is correct is to
use a “greedy stays ahead” argument. This style of proof works by showing that,
according to some measure, the greedy algorithm always is at least as far ahead
as the optimal solution during each iteration of the algorithm. Once you have
established this, you can then use this fact to show that the greedy algorithm
must be optimal.

Typically, you would structure a “greedy stays ahead” argument in four steps:

- **Define your solution**. Your algorithm will produce some object $X$ and you
  will probably compare it against some optimal solution $X*$. Introduce some
  variables denoting your algorithm's solution and the optimal solution.
- **Define your measure**. Your goal is to find a series of measurements you can
  make of your solution and the optimal solution. Define some series of measures
  $m_1(X),m_2(X),\ldots,m_n(X)$ such that $m_1(X*),m_2(X*),\ldots,m_k(X*)$ is
  also defined for some choices of $m$ and $n$. Note that there might be a
  different number of measures for $X$ and $X*$, since you can't assume at this
  point that $X$ is optimal.
- **Prove greedy stays ahead**. Prove that $m_i(X) \ge m_i(X*)$ or
  that $m_i(X) \le m_i(X*)$, whichever is appropriate, for all reasonable values
  of $i$. This argument is usually done inductively.
- **Prove optimality**. Using the fact that greedy stays ahead, prove that the
  greedy algorithm must produce an optimal solution. This argument is often done
  by contradiction by assuming the greedy solution isn't optimal and using the
  fact that greedy stays ahead to derive a contradiction.

When writing up a proof of this form, you don't need to explicitly enumerate
these steps (we didn't do this in lecture, if you'll recall). However, these
steps likely need to be here. If you don't define your solution and the optimal
solution, the notation won't make sense later on. If you don't specify your
measurements, you can't prove anything about them. If you forget to prove that
greedy stays ahead, the rest of your proof can't assume it. Finally, if you
don't prove how the fact that greedy stays ahead implies optimality, you haven't
actually proven what you need to prove (namely, that you get an optimal
solution).

The main challenge with this style of argument is finding the right measurements
to make. If you pick the wrong measurements, you will either get stuck proving
that greedy stays ahead (often because it doesn't always stay ahead!) or proving
that because greedy stays ahead, the algorithm must be optimal (often because
you're using the wrong measurement). As mentioned in lecture, it's often useful
to try showing that if greedy stays ahead according to your measurements, then
the algorithm is optimal before you try actually showing that greedy stays
ahead. That way, you won't end up trying to prove that greedy stays ahead in a
measurement with no bearing on the result.

A few other common pitfalls to watch out for:

- When defining your measurements, make sure that you define them in a way that
  lets you measure the optimal solution you're comparing against, especially if
  that solution wasn't generated by the greedy algorithm. It's typically easy to
  find measurements of the greedy solution because it's generated one step at a
  time; the challenge is figuring out how to determine what specifically those
  measurements are made on. For example, in the interval scheduling problem, the
  measurements made corresponded to the end times of the events as they were
  added to the greedy solution. To make those measurements applicable to the
  arbitrarily-chosen optimal schedule S*, we had to define those measurements on
  an absolute scale: our measurements measured the finishing times of the ith
  event to finish, sorted by order of finishing time.
- Be wary of the case where the greedy solution and optimal solutions don't
  necessarily have the same sizes as one another. In some problems, such as the
  MST problem, all legal spanning trees have the same sizes as one another,
  though they have different costs. In others, such as a the frog jumping
  problem, different solutions might have different numbers of jumps in them. If
  you do use a “greedy stays ahead” argument, you should be sure that you don't
  try showing that your greedy algorithm is better by some measure $m_n$ if the
  optimal solution can only be measured by $k < n$ measurements.
- Although the name of the argument is “greedy stays ahead,” you are usually
  more properly showing that “greedy never falls behind.” That is, you want to
  show that the greedy solution is at least as good as the optimal solution, not
  strictly better than the optimal solution. It takes some practice to know when
  a “greedy stays ahead” proof will be appropriate. Often, these arguments are
  useful when optimal solutions might have different sizes, since you can use
  the fact that greedy stays ahead to explain why your solution must be no
  bigger / no smaller than the optimal solution: if the greedy algorithm
  did / didn't terminate at some step, then the optimal solution at that point
  must be too big / too small and therefore is incorrect. However, there's no
  hard-and-fast rule about where to apply this proof technique, and you'll build
  experience working with it as you work through the problem set on greedy
  algorithms.

## Exchange arguments

Exchange arguments are a powerful and versatile technique for proving optimality
of greedy algorithms. They work by showing that you can iteratively transform
any optimal solution into the solution produced by the greedy algorithm without
changing the cost of the optimal solution, thereby proving that the greedy
solution is optimal.

Typically, exchange arguments are set up as follows:

- **Define your solutions**. You will be comparing your greedy solution $X$ to
  an optimal solution $X*$, so it's best to define these variables explicitly.
- **Compare solutions**. Next, show that if $X ≠ X*$, then they must differ in
  some way. This could mean that there's a piece of $X$ that's not in $X*$, or
  that two elements of $X$ that are in a different order in $X*$, etc. You might
  want to give those pieces names.
- **Exchange pieces**. Show how to transform $X*$ by exchanging some piece
  of $X*$ for some piece of $X$. You'll typically use the piece you described in
  the previous step. Then, prove that by doing so, you did not increase/decrease
  the cost of $X*$ and therefore have a different optimal solution. (You might
  also be able to immediately conclude that you've strictly worsened $X*$, in
  which case you're done. This is uncommon and usually only works if there's
  just one optimal solution.)
- **Iterate**. Argue that you have decreased the number of differences
  between $X$ and $X*$ by performing the exchange, and that by iterating this
  process you can turn $X*$ into $X$ without impacting the quality of the
  solution. Therefore, $X$ must be optimal. (To be very rigorous here, you would
  probably proceed by induction to show this, but for the purposes of this class
  it's fine to hand-wave and explain why you could iteratively transform the
  solution.)
